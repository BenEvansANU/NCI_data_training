{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from pylab import *\n",
    "from datetime import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.9.1.41:8789</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.9.1.41:8820/status' target='_blank'>http://10.9.1.41:8820/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>32</li>\n",
       "  <li><b>Cores: </b>32</li>\n",
       "  <li><b>Memory: </b>67.42 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.9.1.41:8789' processes=32 threads=32, memory=67.42 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client,LocalCluster\n",
    "client =  Client(scheduler_file='scheduler.json')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://github.com/COSIMA/ACCESS-OM2-1-025-010deg-report/blob/master/figures/ice_timeseries/ice_timeseries.ipynb\n",
    "\n",
    "def fixcicetime(da):\n",
    "    '''\n",
    "    Correct the time coordinate in DataArray from CICE netcdf file.\n",
    "    \n",
    "    CICE netcdf files unhelpfully have a time coordinate which is just after the end of the averaging period, \n",
    "    e.g. the time stamp for a January average is 1 February, which messes up groupby month etc.\n",
    "    \n",
    "    This function just subtracts 12 hours to put it in the correct month (and day, for daily means).\n",
    "    \n",
    "    PR 109 gives an option to fix this:\n",
    "    https://github.com/OceansAus/cosima-cookbook/pull/109\n",
    "    \n",
    "    '''\n",
    "    try:\n",
    "        da['time'] = da.time - timedelta64(12, 'h')\n",
    "    except:\n",
    "        da['time'] = da.time - timedelta(hours=12)  # for 01deg which for some reason uses cftime\n",
    "    return da\n",
    "\n",
    "# use this for DataSet: replaces the bad time dimension with the average of time_bounds.\n",
    "#     The time type is also changed to datetime64[ns]\n",
    "#     ds['time'] = ds.time_bounds.astype('int64').mean(axis=1).astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/g/data/v45/hh0162/projects/icebgc/output_access-om2/1deg_jra55_ryf_20190729/output'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/pangeo/2019.10/envs/pangeo/lib/python3.7/site-packages/xarray/core/nanops.py:140: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis=axis, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "griddir = datadir+'001/ocean/ocean_grid.nc'\n",
    "ds_grid = xr.open_dataset(griddir)\n",
    "\n",
    "z_upper = 300\n",
    "\n",
    "dsx = xr.open_dataset(datadir+'001/ocean/ocean.nc')\n",
    "st_ocean = dsx['st_ocean'].sel(st_ocean=slice(0,z_upper))\n",
    "n_upper = size(st_ocean)\n",
    "zmask = dsx.temp.mean('time')/dsx.temp.mean('time')\n",
    "zarea = ds_grid.area_t*zmask\n",
    "\n",
    "#dsx_ice = xr.open_mfdataset(datadir+'001/ice/OUTPUT/*.nc')\n",
    "#zarea = dsx_ice.tarea.mean('time')*zmask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001', '002', '003', '004', '005', '006', '007', '008', '009', '010', '011', '012', '013', '014', '015', '016', '017', '018', '019', '020', '021', '022', '023', '024', '025', '026', '027', '028', '029', '030', '031', '032', '033', '034', '035', '036', '037', '038', '039', '040', '041', '042', '043', '044', '045', '046', '047', '048', '049', '050', '051', '052', '053', '054', '055', '056', '057', '058', '059', '060', '061', '062', '063', '064']\n"
     ]
    }
   ],
   "source": [
    "n_yrs = 500 \n",
    "exp0 = 1\n",
    "exp1 = 64\n",
    "l_exp = []\n",
    "for it in arange(exp0,exp1+1):\n",
    "    if it < 10:\n",
    "        l_exp.append('00'+str(it))\n",
    "    elif it > 9 or it < 100:\n",
    "        l_exp.append('0'+str(it))\n",
    "    else:\n",
    "        l_exp.append(str(it))\n",
    "print(l_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1docean = [\n",
    "    'total_co2_flux',\n",
    "    'temp_global_ave',\n",
    "    'salt_global_ave',\n",
    "    'temp_surface_ave',\n",
    "    'salt_surface_ave',\n",
    "]\n",
    "\n",
    "uni1docean = [\n",
    "    'Pg/Yr',\n",
    "    'deg.C',\n",
    "    'psu',\n",
    "    'deg.C',\n",
    "    'psu'\n",
    "]\n",
    "\n",
    "var3docean = [\n",
    "    'temp',\n",
    "    'salt',\n",
    "    'no3',\n",
    "    'phy',\n",
    "    'zoo',\n",
    "    'det',\n",
    "    'fe',\n",
    "    'o2',\n",
    "    'alk',\n",
    "    'dic',\n",
    "    'adic',\n",
    "    'caco3'\n",
    "]\n",
    "\n",
    "uni3docean = [\n",
    "    'deg.C',\n",
    "    'psu',\n",
    "    'mmol/m3',\n",
    "    'mmol-N/m3',\n",
    "    'mmol-N/m3',\n",
    "    'mmol-N/m3',\n",
    "    'mmol/m3',\n",
    "    'mmol/m3',\n",
    "    'mmol/m3',\n",
    "    'mmol/m3',\n",
    "    'mmol/m3',\n",
    "    'mmol/m3'\n",
    "]\n",
    "\n",
    "var2dice = [\n",
    "#    'Tair_m',\n",
    "    'aice_m',\n",
    "    'hs_m',\n",
    "    'hi_m',\n",
    "]\n",
    "\n",
    "uni2dice = [\n",
    "#    'deg.C',\n",
    "    '10$^6$ km$^2$',\n",
    "    '10$^3$ km$^3$',\n",
    "    '10$^3$ km$^3$',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### northern and southern hemisphere ice quantities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20190902: latitude slice does not work because dimension \"nj\" is not in degree N/S, but is simply indices. not suitable for xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsx['yt_ocean'] = ds_grid.yt_ocean.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/pangeo/2019.10/envs/pangeo/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: In xarray version 0.14 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  import sys\n",
      "/apps/pangeo/2019.10/envs/pangeo/lib/python3.7/site-packages/xarray/backends/api.py:934: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/pangeo/2019.10/envs/pangeo/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: In xarray version 0.14 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  import sys\n",
      "/apps/pangeo/2019.10/envs/pangeo/lib/python3.7/site-packages/xarray/backends/api.py:934: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/pangeo/2019.10/envs/pangeo/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: In xarray version 0.14 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  import sys\n",
      "/apps/pangeo/2019.10/envs/pangeo/lib/python3.7/site-packages/xarray/backends/api.py:934: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/pangeo/2019.10/envs/pangeo/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: In xarray version 0.14 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  import sys\n",
      "/apps/pangeo/2019.10/envs/pangeo/lib/python3.7/site-packages/xarray/backends/api.py:934: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/pangeo/2019.10/envs/pangeo/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: In xarray version 0.14 the default behaviour of `open_mfdataset`\n",
      "will change. To retain the existing behavior, pass\n",
      "combine='nested'. To use future default behavior, pass\n",
      "combine='by_coords'. See\n",
      "http://xarray.pydata.org/en/stable/combining.html#combining-multi\n",
      "\n",
      "  import sys\n",
      "/apps/pangeo/2019.10/envs/pangeo/lib/python3.7/site-packages/xarray/backends/api.py:934: FutureWarning: The datasets supplied have global dimension coordinates. You may want\n",
      "to use the new `combine_by_coords` function (or the\n",
      "`combine='by_coords'` option to `open_mfdataset`) to order the datasets\n",
      "before concatenation. Alternatively, to continue concatenating based\n",
      "on the order the datasets are supplied in future, please use the new\n",
      "`combine_nested` function (or the `combine='nested'` option to\n",
      "open_mfdataset).\n",
      "  from_openmfds=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/64\n"
     ]
    }
   ],
   "source": [
    "#calculating\n",
    "if 1 == 1:\n",
    "    ts_air = zeros((n_yrs))\n",
    "    ts_ice = zeros((size(var2dice),2,n_yrs))\n",
    "    i_yr = 0\n",
    "    for it in arange(0,5):#size(l_exp)):\n",
    "        dsx = xr.open_mfdataset(datadir+l_exp[it]+'/ice/OUTPUT/*.nc')\n",
    "        fixcicetime(dsx)\n",
    "        dsx = dsx.groupby('time.year').mean('time')\n",
    "        for it2 in range(size(var2dice)):\n",
    "            ice_volume = (dsx[var2dice[it2]]*dsx.tarea.values)\n",
    "            #Northern Hemisphere\n",
    "            ts_ice[it2,0,i_yr:i_yr+size(ice_volume,0)] = sum(ice_volume.sel(nj=slice(30,90)),axis=(1,2))\n",
    "            #Southern Hemisphere\n",
    "            ts_ice[it2,1,i_yr:i_yr+size(ice_volume,0)] = sum(ice_volume.sel(nj=slice(-90,-30)),axis=(1,2))\n",
    "        #global surface air temperature\n",
    "        ice_volume = (dsx['Tair_m']*dsx.tarea.values*dsx.tmask.values)\n",
    "        ts_air[i_yr:i_yr+size(ice_volume,0)] = sum(ice_volume,axis=(1,2))/sum(dsx.tarea.values*dsx.tmask.values)  \n",
    "        i_yr += size(ice_volume,0)\n",
    "        save('ts_ice',ts_ice)\n",
    "        save('ts_air',ts_air)\n",
    "        print(str(it)+'/'+str(size(l_exp)))\n",
    "#plotting\n",
    "else:\n",
    "    #plot air temp.\n",
    "    ts_air = load('ts_air.npy')\n",
    "    figure()\n",
    "    title(var2dice[0])\n",
    "    plot(arange(n_yrs),ts_air)\n",
    "    xlabel('Year')\n",
    "    ylabel('deg.C')\n",
    "    savefig('ts_air.pdf',dpi=300)\n",
    "    #plot ice\n",
    "    ts_ice = load('ts_ice.npy') * 1e-12\n",
    "    figure(figsize=(12,8))\n",
    "    for it in range(size(ts_ice,0)):\n",
    "        subplot(size(ts_ice,0),1,it+1)\n",
    "        title(var2dice[it])\n",
    "        plot(arange(n_yrs),ts_ice[it,0,:],label='NH')\n",
    "        plot(arange(n_yrs),ts_ice[it,1,:],label='SH')\n",
    "        xlabel('Year')\n",
    "        ylabel(uni2dice[it])\n",
    "        if it == 0:\n",
    "            legend()\n",
    "    tight_layout()\n",
    "    savefig('ts_ice.pdf',dpi=300)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time series of 3d ocean fields in the upper X m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/63 done.\n",
      "1/63 done.\n",
      "2/63 done.\n",
      "3/63 done.\n",
      "4/63 done.\n",
      "5/63 done.\n",
      "6/63 done.\n",
      "7/63 done.\n",
      "8/63 done.\n",
      "9/63 done.\n",
      "10/63 done.\n",
      "11/63 done.\n",
      "12/63 done.\n",
      "13/63 done.\n",
      "14/63 done.\n",
      "15/63 done.\n",
      "16/63 done.\n",
      "17/63 done.\n",
      "18/63 done.\n",
      "19/63 done.\n",
      "20/63 done.\n",
      "21/63 done.\n",
      "22/63 done.\n",
      "23/63 done.\n",
      "24/63 done.\n",
      "25/63 done.\n",
      "26/63 done.\n",
      "27/63 done.\n",
      "28/63 done.\n",
      "29/63 done.\n",
      "30/63 done.\n",
      "31/63 done.\n",
      "32/63 done.\n",
      "33/63 done.\n",
      "34/63 done.\n",
      "35/63 done.\n",
      "36/63 done.\n",
      "37/63 done.\n",
      "38/63 done.\n",
      "39/63 done.\n",
      "40/63 done.\n",
      "41/63 done.\n",
      "42/63 done.\n",
      "43/63 done.\n",
      "44/63 done.\n",
      "45/63 done.\n",
      "46/63 done.\n",
      "47/63 done.\n",
      "48/63 done.\n",
      "49/63 done.\n",
      "50/63 done.\n",
      "51/63 done.\n",
      "52/63 done.\n",
      "53/63 done.\n",
      "54/63 done.\n",
      "55/63 done.\n",
      "56/63 done.\n",
      "57/63 done.\n",
      "58/63 done.\n",
      "59/63 done.\n",
      "60/63 done.\n",
      "61/63 done.\n",
      "62/63 done.\n",
      "63/63 done.\n"
     ]
    }
   ],
   "source": [
    "#calculating time series\n",
    "if 1 == 1:\n",
    "    ts_bgc = zeros((size(var3docean),n_yrs,n_upper))\n",
    "    i_yr = 0    \n",
    "    for it in arange(0,exp1-exp0+1):\n",
    "        dsx = xr.open_dataset(datadir+l_exp[it]+'/ocean/ocean.nc',chunks={'st_ocean': None})\n",
    "        for it2 in range(size(var3docean)):\n",
    "            ice_volume = (dsx[var3docean[it2]].sel(st_ocean=slice(0,z_upper))*zarea)\n",
    "            iv_nh = ice_volume.sum(dim='yt_ocean').sum(dim='xt_ocean')/zarea.sum(dim='yt_ocean').sum('xt_ocean')\n",
    "            ts_bgc[it2,i_yr:i_yr+size(iv_nh,0),:] = iv_nh\n",
    "        i_yr += size(iv_nh,0)\n",
    "        save('ts_bgc',ts_bgc)\n",
    "        print(str(it)+'/'+str(exp1-exp0)+' done.')\n",
    "    ts_bgc[0,:,:] = ts_bgc[0,:,:] - 273.15\n",
    "#plotting time series\n",
    "else:\n",
    "    ts_bgc = load('ts_bgc.npy')\n",
    "    figure(figsize=(15,8))\n",
    "    for it in range(size(ts_bgc,0)):\n",
    "        subplot(3,4,it+1)\n",
    "        pcolormesh(arange(n_yrs),st_ocean,ts_bgc[it,:,:].T,rasterized=True)\n",
    "        gca().invert_yaxis()\n",
    "        colorbar(orientation='horizontal',label=var3docean[it]+' ('+uni3docean[it]+')')        \n",
    "        xlabel('Year')\n",
    "        ylabel('Depth (m)')\n",
    "    tight_layout()\n",
    "    savefig('ts_bgc.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### average over upper 100 m to assess the stability more precisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/63 done.\n",
      "1/63 done.\n",
      "2/63 done.\n",
      "3/63 done.\n",
      "4/63 done.\n",
      "5/63 done.\n",
      "6/63 done.\n",
      "7/63 done.\n",
      "8/63 done.\n",
      "9/63 done.\n",
      "10/63 done.\n",
      "11/63 done.\n",
      "12/63 done.\n"
     ]
    }
   ],
   "source": [
    "#calculating time series\n",
    "if 1 == 1:\n",
    "    ts_bgc = zeros((size(var3docean),n_yrs))\n",
    "    i_yr = 0    \n",
    "    for it in arange(0,exp1-exp0+1):\n",
    "        dsx = xr.open_dataset(datadir+l_exp[it]+'/ocean/ocean.nc')\n",
    "        for it2 in range(size(var3docean)):\n",
    "            ice_volume = (dsx[var3docean[it2]].sel(st_ocean=slice(0,100))*zarea.sel(st_ocean=slice(0,100)))\n",
    "            iv_nh = sum(ice_volume,axis=(1,2,3))/sum(zarea.sel(st_ocean=slice(0,100)))\n",
    "            ts_bgc[it2,i_yr:i_yr+size(iv_nh)] = iv_nh\n",
    "        i_yr += size(iv_nh)\n",
    "        save('ts_bgc_upper100',ts_bgc)\n",
    "        print(str(it)+'/'+str(exp1-exp0)+' done.')\n",
    "    ts_bgc[0,:] = ts_bgc[0,:] - 273.15\n",
    "#plotting time series\n",
    "else:\n",
    "    ts_bgc = load('ts_bgc_upper100.npy')\n",
    "    figure(figsize=(15,8))\n",
    "    for it in range(size(ts_bgc,0)):\n",
    "        subplot(3,4,it+1)\n",
    "        plot(arange(n_yrs),ts_bgc[it,:])\n",
    "        xlabel('Year')\n",
    "        ylabel(var3docean[it]+' ('+uni3docean[it]+')')\n",
    "    tight_layout()\n",
    "    savefig('ts_bgc_upper100.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time series of globally averaged ocean fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating time series\n",
    "if 1 == 1:\n",
    "    ts_1docean = zeros((size(var1docean),n_yrs))\n",
    "    i_yr = 0\n",
    "    for it in arange(0,exp1-exp0+1):\n",
    "        dsx = xr.open_dataset(datadir+l_exp[it]+'/ocean/ocean_scalar.nc')\n",
    "        for it2 in range(size(var1docean)):\n",
    "            ave_1y = squeeze(dsx[var1docean[it2]].groupby('time.year').mean('time'))\n",
    "            ts_1docean[it2,i_yr:i_yr+size(ave_1y)] = ave_1y\n",
    "        i_yr += size(ave_1y)\n",
    "        print(str(it)+'/'+str(exp1-exp0)+' done.')\n",
    "    save('ts_1docean',ts_1docean)\n",
    "#plotting time series\n",
    "else:\n",
    "    ts_1docean = load('ts_1docean.npy')\n",
    "    figure(figsize=(12,8))\n",
    "    for it in range(size(ts_1docean,0)):\n",
    "        subplot(3,2,it+2)\n",
    "        title(var1docean[it])\n",
    "        plot(arange(n_yrs),ts_1docean[it,:])\n",
    "        xlabel('Year')\n",
    "        ylabel(uni1docean[it])\n",
    "    tight_layout()\n",
    "    savefig('ts_1docean.pdf',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsx.salt_global_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the PBS job.\n",
    "! pangeo.end.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
