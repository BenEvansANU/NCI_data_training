{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](../../_static/images/NCI_logo.png)\n",
    "\n",
    "-------\n",
    "\n",
    "# Setup Pangeo Environment\n",
    "\n",
    "\n",
    "In this notebook:\n",
    "\n",
    "- Load Pangeo module\n",
    "- Activate pangeo enviornment\n",
    "- submit a batch job script to the queue system\n",
    "- Set up port forwarding at the client machine\n",
    "- Connect to the remote Jupyter lab server from client machine\n",
    "- Utilise the dask server in Jupyter notebook\n",
    "- Visulise dask dashboard\n",
    "- Run Jupyter notebook in a batch job\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "**Pangeo** is a community platform for big data in geoscience, funded by US NSF. Pangeo project serves as a coordination point between scientists, software and computing infrastructure. The Pangeo software ecosystem involves open source tools such as xarray, iris, dask, jupyter, and many other packages. [This site](http://pangeo.io) provides guidance for accessing data and performing analysis using these tools. NCI has installed the Pangeo environment on Raijin by following instructions [here](http://pangeo.io/setup_guides/hpc.html). Please note that Pangeo will be transferred to Gadi when major Raijin/Gadi transition happens in Nov/Dec. It will not be available on Raijin from transition period onwards. This notebook provides instructions on how to use the Pangeo environment to run your jupyter notebook locally and interact with Raijin remotely on Raijin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pangeo module from Raijin and activate Pangeo environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ module load pangeo/2019.10\n",
    "$ source ${PANGEO_ROOT}/etc/profile.d/conda.sh\n",
    "$ conda activate pangeo\n",
    "```\n",
    "You will see pangeo appear in the bracets in front of the promt sign. You can quit the enviornment using **conda deactivate**\n",
    "\n",
    "```\n",
    "$codna deactivate\n",
    "```\n",
    "\n",
    "![1](images/pangeo_setup1.png)\n",
    "\n",
    "If you ask where your Python command lives, it should direct you to where pangeo was installed on Raijin. \n",
    "\n",
    "![2](images/pangeo_setup2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following two lines of command.\n",
    "\n",
    "```\n",
    "$ jupyter notebook --generate-config\n",
    "$ jupyter notebook password\n",
    "```\n",
    "It will promote you to enter a password for opening jupyter notebook on your local machine later. You can simply type a password and you need to remember it!\n",
    "\n",
    "If the command does not work (often in older versions of Jupyter), there are [instructions](http://pangeo.io/setup_guides/hpc.html) on how to set up step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a Jupyter Notebook Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a directory where you will run the jupyter notebook, let's call it \"tutorial\". \n",
    "\n",
    "Submit a batch job script as below to the queue system. You can create a shell script by copying the following commands into a script file. Let's name it as run_ipynb_job.sh. Or you can download the example script here. We request 2 notes with 32 CPU and 64GB memory in this instance. Further instructions  about job submission and running jobs on Raijin can be found [here](https://opus.nci.org.au/display/Help/Running+Jobs).\n",
    "\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "#PBS -N pangeo_test\n",
    "#PBS -P $YOUR_PROJECT_ID\n",
    "#PBS -q express\n",
    "#PBS -l walltime=5:00:00\n",
    "#PBS -l ncpus=32\n",
    "#PBS -l mem=64GB\n",
    "#PBS -l jobfs=100GB\n",
    "module load pangeo/2019.10\n",
    "pangeo.ini.all.sh\n",
    "sleep infinity\n",
    "```\n",
    "\n",
    "![3](images/pangeo_setup3.png)\n",
    "\n",
    "Replace the requested resources, queue type and project ID with those suitable for you. Please always request one or multiple whole nodes in your job script. The above job will load the pangeo module, run the initialization script called **pangeo.ini.all.sh**, and keep alive in the job lifetime. The initialization script will set up the dask scheduler at one node and multiple workers on all nodes. After that, it will start up the jupyter lab and create port forwarding commands for the user by putting them into a file named ‘client_cmd’ . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up port forwarding at the client machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the job is complete, there are two files appearing in your current directory. \n",
    "\n",
    "* client_cmd\n",
    "* scheduler.json\n",
    "\n",
    "![4](images/pangeo_setup4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file client_cmd contains commands to forward network traffics from the defined port number of worker node to client machine via the login node raijin.nci.org.au. In the example below, jupyter lab uses port 8343 and dask dashboard occupies port 8890 respectively at the Raijin worker node r225. Note both port numbers are randomly picked up in each job so they keep changing in different job submissions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSH login with/without password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have set up the SSH login without password you could paste the above two lines in one command line interface (CLI) of the client machine (recommend to use VDI or a computer with MAC OS or Linux). \n",
    "\n",
    "![5](images/pangeo_setup5.png)\n",
    "\n",
    "Otherwise, you may need to run each command in separate CLIs and type in your Raijin password when needed: \n",
    " \n",
    "CLI_1: \n",
    "```\n",
    "$ ssh -N -L 8343:r225:8343 jbw900@raijin.nci.org.au \n",
    "jbw900@raijin.nci.org.au's password: \n",
    "```\n",
    "\n",
    "CLI_2: \n",
    "```\n",
    "$ ssh -N -L 8890:r225:8890 jbw900@raijin.nci.org.au \n",
    "jbw900@raijin.nci.org.au's password: \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the remote Jupyter lab server from your client machine\n",
    "\n",
    "By typing in “localhost:8343” in a web browser of client machine, you could enter the remote jupyter lab interface. \n",
    "\n",
    "![6](images/pangeo_setup6.png)\n",
    "\n",
    "Then it will prompt the password. Type the password that you set up in the second step in this tutorial. \n",
    "\n",
    "![7](images/pangeo_setup7.png)\n",
    "\n",
    "Once your authentication passed, a jupyterlab interface will be launched in a few seconds.\n",
    "\n",
    "![8](images/pangeo_setup8.png)\n",
    "\n",
    "Now you are ready to run your own notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's import a notebook example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can drag and drop a notebook from your local computer into this Jupyterlab. Then the file will also appear in your working directory in Raijin. \n",
    "\n",
    "![9](images/pangeo_setup9.png)\n",
    "\n",
    "The screen shot above shows\n",
    "\n",
    "- left: jupyter notebook interface\n",
    "- up right: local dir where a notebook is dragged and dropped into the Jupyterlab\n",
    "- down right: Raijin command window showing the notebook appears instantly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilize the dask server in Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To utilize the dask server established from the PBS job, it is necessary to add and run the following cell at the beginning of your notebook: \n",
    "\n",
    "```\n",
    "from dask.distributed import Client,LocalCluster \n",
    "client = Client(scheduler_file='scheduler.json') \n",
    "print(client) \n",
    "```\n",
    "\n",
    "Its output will show configurations of client and cluster. Make sure the number of cores matches what you requested in the job script. Now you could run your notebook as usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminate the job\n",
    "\n",
    "After all work finished, add and run a cell as below to stop the job.\n",
    "\n",
    "```\n",
    "!pangeo.end.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap important notes\n",
    "\n",
    "Please make sure the following two lines are added at the beginning and the end of the notebook.\n",
    "\n",
    "```\n",
    "# start the dask client\n",
    "client =  Client(scheduler_file='scheduler.json')\n",
    " \n",
    "# stop the pbs job.\n",
    "! pangeo.end.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View threads using Dask dashboard\n",
    "\n",
    "Open a new tab in the web browser, type the following, the second port in the client_cmd file. \n",
    "If the job starts running, you should be able to see the dynamic resources of the processing.\n",
    "\n",
    "```\n",
    "localhost:8890\n",
    "```\n",
    "![10](images/pangeo_setup10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Jupyter notebook in a batch job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert your jupyter notebook to a python script\n",
    "\n",
    "```\n",
    "jupyter nbconvert --to script [YOUR_NOTEBOOK}.ipynb\n",
    "```\n",
    "\n",
    "Make sure you have added the following lines at the beginning of the python script.\n",
    "\n",
    "```\n",
    "from dask.distributed import Client,LocalCluster \n",
    "client = Client(scheduler_file='scheduler.json') \n",
    "print(client) \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the job script as below\n",
    "\n",
    "```\n",
    "#!/bin/bash \n",
    "#PBS -N pangeo_test \n",
    "#PBS -P YOUR_PROJECT_ID \n",
    "#PBS -q YOUR_QUEUE_TYPE \n",
    "#PBS -l walltime=5:00:00 \n",
    "#PBS -l ncpus=32 \n",
    "#PBS -l mem=64GB \n",
    "#PBS -l jobfs=100GB \n",
    " \n",
    "module load pangeo/2019.10 \n",
    "pangeo.ini.all.sh \n",
    "source ${PANGEO_ROOT}/etc/profile.d/conda.sh \n",
    "conda activate pangeo \n",
    " \n",
    "cd $PBS_O_WORKDIR \n",
    "python YOUR_PYSCRIPT_NAME.py \n",
    "pangeo.end.sh\n",
    "```\n",
    "\n",
    "Modify parameters that suit your case, and name it as **run_py.sh**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit your job script via 'qsub' command\n",
    "\n",
    "```\n",
    "qsub run_py.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "- http://pangeo.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
