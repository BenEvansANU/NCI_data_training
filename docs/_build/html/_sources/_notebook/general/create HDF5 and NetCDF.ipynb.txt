{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](../../_static/images/NCI_logo.png)\n",
    "\n",
    "-------\n",
    "\n",
    "# Create HDF and netCDF files \n",
    "\n",
    "\n",
    "\n",
    "### In this notebook:\n",
    "\n",
    "* Python libraries list\n",
    "\n",
    "* How to write HDF and netCDF files\n",
    "\n",
    "* Opening file and viewing contents\n",
    "\n",
    "* Command-line tools for HDF5 files\n",
    "    \n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the Jupyter Notebook application\n",
    "\n",
    "**Using pre-built VDI modules:**\n",
    "\n",
    "Load the following modules:\n",
    "\n",
    "```\n",
    "    $ module load python3\n",
    "    $ module load python3/3.5.2-matplotlib\n",
    "    $ module load ipython/4.2.0-py3.5\n",
    "    $ module load netcdf/4.3.3.1\n",
    "    $ module load netcdf4-python/1.2.4-ncdf-4.3.3.1-py3.5\n",
    "    $ module load h5py/2.6.0-hdf5-1.8.14-py3.5\n",
    "```    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "from numpy.random import uniform\n",
    "import h5py\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to write HDF5 and NetCDF files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF (Heirarchical Data Format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first work on creating a HDF5 (Heirarchical Data Format) file. HDF5 is a powerful binary data format with no upper limit on the file size. It provides parallel IO and runs under the hood low level optimisations to make queries faster and storage requirements smaller. HDF5 files work generally like standard Python file objects. They support standard modes like r/w/a, and should be closed when they are no longer in use.\n",
    "\n",
    "We have to initialise our HDF5 file using <span style=\"color:red\">h5py.File</span> and providing the arguments of filename and mode. As we are writing this file, we provide a __w__ for write access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file = h5py.File(\"geosurvey1.hdf5\", \"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file name may be a byte string or unicode string. \n",
    "\n",
    "| Valid modes        | Description           |\n",
    "| ------------- |:-------------:|\n",
    "| r   | Readonly, file must exist |\n",
    "| r+      | Read/write, file must exist      |\n",
    "| w | Create file, truncate if exists      |\n",
    "| w- or x | Create file, fail if exists |\n",
    "| a | Read/write if exists, create otherwise (default)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create an HDF5 dataset. Datasets are very similar to NumPy arrays in that they are homogeneous collections of data elements, with an immutable datatype and (hyper)rectangular shape. HDF5 datasets support a variety of transparent storage features (e.g. compression, error-dection and chunked I/O)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New datasets are created using either <span style=\"color:red\">Group.create_dataset( )</span> or <span style=\"color:red\">Group.require_dataset( )</span>. To make an empty dataset, one must specify a name, shape and (optionally) the data type (default is 'f'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    " dset1 = h5file.create_dataset(\"Zxx\", (1000,), dtype='i')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 datasets have both a shape and data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset1.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to initialise the dataset to an existing NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "initdata = np.arange(0,1,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset2 = h5file.create_dataset(\"Zxy\", data=initdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset3 = h5file.create_dataset(\"Zyx\", data=initdata, dtype='f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 datasets are by default contiguous. However, datasets can be created using HDF5's chunked storage layout. This means the dataset is divided up into regularly-sized pieces which are stored haphazardly on disk, and indexed using a B-tree.\n",
    "\n",
    "Chunked storage makes it possible to resize datasets, allowing compression filters. To enable chunked storage, set the keyword <span style=\"color:red\">chunk</span> to a tuple indicating the chunk shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset4 = h5file.create_dataset(\"Zyy\", (1000,1000), chunks=(100,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, data will be read and written in blocks with shape (100,100). Since picking a chunk shape can be confusing, h5py can guess a chunk shape for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset5 = h5file.create_dataset(\"Zyyb\", (1000,1000), chunks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,) (1000,) (1000,) (1000, 1000) (1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(dset1.shape, dset2.shape, dset3.shape, dset4.shape, dset5.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Groups and heirarchical organisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every object in an HDF5 file has a name, and they're arranged in a POSIX-style hierarchy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Zyx'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset3.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"folders\" in this system are called <span style=\"color:red\">groups</span>. Let's now create a subgroup using <span style=\"color:red\">create_group</span> and add some other datasets to this subgroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "group1 = h5file.create_group(\"survey1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey1g = group1.create_dataset(\"gravity_data\", (50,), dtype = 'f')\n",
    "survey1m = group1.create_dataset(\"magnetic_data\", (50,), dtype = 'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/survey1/magnetic_data'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey1g.name\n",
    "survey1m.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify the full path when creating the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey1a = h5file.create_dataset(\"survey1/airborneEM_data\", (10,), dtype='i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/survey1/airborneEM_data'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey1a.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve objects in the file using the item-relevant syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = h5file['survey1/gravity_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's list all the groups in our file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zxx\n",
      "Zxy\n",
      "Zyx\n",
      "Zyy\n",
      "Zyyb\n",
      "survey1\n"
     ]
    }
   ],
   "source": [
    "for name in h5file:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One great feature of HDF5 is that you can store metadata right next to the data it describes. All groups and datasets support attached named bits of data called *attributes*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset1.attrs['latitude'] = 32.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset1.attrs['longitude'] = 144.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'longitude' in dset1.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we need to do now is close the file, which will write all our work to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetCDF (Network Common Data Form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NetCDF is a data storage format commonly used within the geoscience community. The acronym stands for Network Common Data Format and it refers to a \"set of software libraries and self-describing, machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data\"(http://netcdf4-python.googlecode.com/svn/trunk/docs/netCDF4-module.html).\n",
    "\n",
    "One of the main advantages of using NetCDF is that it has a built-in hierarchical structure that facilitates better organization and documentation of data. It is well suited to handle large numerical datasets as it allows users to access portions of a dataset without loading its entirety into memory.\n",
    "\n",
    "Now let's create a netCDF file. For this we are going to use the netCDF4-python module. To create a netCDF file from python, use the  <span style=\"color:red\">Dataset( )</span> constructor. This method is also used to open an existing netCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "netCDF_file = Dataset('oceantemp.nc','w',format='NETCDF4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "netCDF_file is a netCDF Dataset object that provides methods for storing data to the file. netCDF_file also doubles as the root group. A netCDF group is basically a directory or folder within the netCDF dataset. This allows you to organize data as you would in a unix file system. Let's create a group for the heck of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempgrp = netCDF_file.createGroup('area1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETCDF4\n"
     ]
    }
   ],
   "source": [
    "print(netCDF_file.file_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a set of dimensions used for your variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "hight = netCDF_file.createDimension('hight', 20)\n",
    "lat = netCDF_file.createDimension('lat', 22)\n",
    "lon = netCDF_file.createDimension('lon', 28)\n",
    "time = netCDF_file.createDimension('time', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first and second arguments of the createDimension method are the dimension's name and length, respectively. In the last line, time is added as a dimension. This gives the option of constructing a four dimensional array with time as the extra dimension. By using None as the second argument, time is made as an unlimited dimension. An unlimited dimension is one that can grow indefinitely; the other dimensions, with their specified lengths, are locked into their current size. The netCDF4 format permits multiple unlimited dimensions, but older formats allow only one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 22 0\n"
     ]
    }
   ],
   "source": [
    "print(len(lon), len(lat),len(time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dimensions__: All of the *Dimension* instances are stored in a python dictionary. Therefore, we can access each dimension by its name using dictionary key access: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lon dimension: <class 'netCDF4._netCDF4.Dimension'>: name = 'lon', size = 28\n",
      "\n",
      "Lat dimension: <class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 22\n",
      "\n",
      "Hight dimension: <class 'netCDF4._netCDF4.Dimension'>: name = 'hight', size = 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Lon dimension:', netCDF_file.dimensions['lon'])\n",
    "print('Lat dimension:', netCDF_file.dimensions['lat'])\n",
    "print('Hight dimension:', netCDF_file.dimensions['hight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hight 20 False\n",
      "lat 22 False\n",
      "lon 28 False\n",
      "time 0 True\n"
     ]
    }
   ],
   "source": [
    "for dimname in netCDF_file.dimensions.keys():\n",
    "    dim = netCDF_file.dimensions[dimname]\n",
    "    print(dimname, len(dim), dim.isunlimited())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Variables__: NetCDF variables behave much like python multi-dimensional arrays in numpy. However, unlike numpy arrays, netCDF variables can be appended to along the *unlimited* dimension. To create a netCDF variable, use <span style=\"color:red\">Dataset.createVariable(*var_id*, *type*, *dimensions*)</span>:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = netCDF_file.createVariable('time', np.float64, ('time'))\n",
    "latitudes = netCDF_file.createVariable('latitude', np.float32, ('lat',))\n",
    "longitudes = netCDF_file.createVariable('longitude', np.float32, ('lon',))\n",
    "hights = netCDF_file.createVariable('hight', np.float32, ('hight',))\n",
    "\n",
    "# create the actual 4-D variable\n",
    "temperature = netCDF_file.createVariable('temperature', np.float32, ('time','lat','lon','hight'))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The first argument supplies the name of the variable, the second argument sets the datatype and the third argument sets the shape. \"np.float64\" specifies a 64 bit float. The shapes of the variables are specified using the dimension names. To create a scalar variable, one would omit the third argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Variable'>\n",
       "float32 temperature(time, lat, lon, hight)\n",
       "unlimited dimensions: time\n",
       "current shape = (0, 22, 28, 20)\n",
       "filling on, default _FillValue of 9.969209968386869e+36 used"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the variables in the *Dataset* are stored in a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat variable: <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 latitude(lat)\n",
      "unlimited dimensions: \n",
      "current shape = (22,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('lat variable:', netCDF_file.variables['latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time float64 ('time',) (0,)\n",
      "latitude float32 ('lat',) (22,)\n",
      "longitude float32 ('lon',) (28,)\n",
      "hight float32 ('hight',) (20,)\n",
      "temperature float32 ('time', 'lat', 'lon', 'hight') (0, 22, 28, 20)\n"
     ]
    }
   ],
   "source": [
    "for varname in netCDF_file.variables.keys():\n",
    "    var = netCDF_file.variables[varname]\n",
    "    print(varname, var.dtype, var.dimensions, var.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Attributes (global)__: Global attributes are set by assigning values to *Dataset* instance variables. Attributes can be strings, numbers or sequences.\n",
    "\n",
    "__Attributes (variable)__: Variable attributes are set by assigning to *Variable* instance variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Attributes\n",
    "\n",
    "netCDF_file.description = 'some fake ocean temperature data'\n",
    "#dataset_nCDF.history = 'Created'+ today.strftime(\"%d/%m/%y\")\n",
    "netCDF_file.source = 'netCDF4 python module tutorial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable attributes\n",
    "\n",
    "latitudes.units='degree_north'\n",
    "longitudes.units='degree_east'\n",
    "times.units='hours since 0001-01-01 00:00:00'\n",
    "times.calendar='gregorian'\n",
    "hights.units='meters'\n",
    "temperature.units='Kelvin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some fake ocean temperature data\n"
     ]
    }
   ],
   "source": [
    "print(netCDF_file.description)\n",
    "#print(dataset_nCDF.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Writing Data__: To put data into our netCDF Variables, we can assign data to a slice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = np.arange(-30,25,2.5)\n",
    "lons = np.arange(45,101,2)\n",
    "hights = np.arange(0,200,10)\n",
    "latitudes[:] = lats\n",
    "longitudes[:] = lons\n",
    "periods[:] = periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitudes =\n",
      " [-30.  -27.5 -25.  -22.5 -20.  -17.5 -15.  -12.5 -10.   -7.5  -5.   -2.5\n",
      "   0.    2.5   5.    7.5  10.   12.5  15.   17.5  20.   22.5]\n",
      "longitudes =\n",
      " [45. 47. 49. 51. 53. 55. 57. 59. 61. 63. 65. 67. 69. 71. 73. 75. 77. 79.\n",
      " 81. 83. 85. 87. 89. 91. 93. 95. 97. 99.]\n"
     ]
    }
   ],
   "source": [
    "print('latitudes =\\n', latitudes[:])\n",
    "print('longitudes =\\n', longitudes[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NetCDF *variable* objects that have an unlimited dimension will grow along that dimension if you assign data outside the currently defined range of indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature shape before adding data = (0, 22, 28, 20)\n"
     ]
    }
   ],
   "source": [
    "print('temperature shape before adding data =', temperature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlats = len(netCDF_file.dimensions['lat'])\n",
    "nlons = len(netCDF_file.dimensions['lon'])\n",
    "nhights = len(netCDF_file.dimensions['hight'])\n",
    "temperature[1:10,:,:,:] = uniform(size=(9,nlats,nlons,nhights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Time coordinates__: Most metadata standards (e.g. CF, COARDS) specify that time be measured relative to a fixed date using a certain calendar (e.g. hours since YY:MM:DD hh-mm-ss\"). The functions <span style=\"color:red\">num2date( )</span> and <span style=\"color:red\">date2num( )</span> can be used to convert values to and from calendar dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import num2date, date2num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "\n",
    "for n in range(temperature.shape[0]):\n",
    "    dates.append(datetime(2000,1,1)+ n*timedelta(hours=12))\n",
    "\n",
    "times[:] = date2num(dates, units = times.units, calendar = times.calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time values (in units hours since 0001-01-01 00:00:00):\n",
      " [17522904. 17522916. 17522928. 17522940. 17522952. 17522964. 17522976.\n",
      " 17522988. 17523000. 17523012.]\n"
     ]
    }
   ],
   "source": [
    "print('time values (in units %s):'% times.units + '\\n', times[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = num2date(times[:], units = times.units, calendar=times.calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates corresponding to time values:\n",
      " [real_datetime(2000, 1, 1, 0, 0) real_datetime(2000, 1, 1, 12, 0)\n",
      " real_datetime(2000, 1, 2, 0, 0) real_datetime(2000, 1, 2, 12, 0)\n",
      " real_datetime(2000, 1, 3, 0, 0) real_datetime(2000, 1, 3, 12, 0)\n",
      " real_datetime(2000, 1, 4, 0, 0) real_datetime(2000, 1, 4, 12, 0)\n",
      " real_datetime(2000, 1, 5, 0, 0) real_datetime(2000, 1, 5, 12, 0)]\n"
     ]
    }
   ],
   "source": [
    "print('dates corresponding to time values:\\n', dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Finally, we need to write the file:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "netCDF_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the file is written."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening file and viewing contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first begin with a HDF file. For this example we will use the same file we previously created. To open and read data, use the <span style=\"color:red\">File</span> method in read mode, *r*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = h5py.File('geosurvey1.hdf5','r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what data is in the file by using the call <span style=\"color:red\">keys()</span> on the file object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['Zxx', 'Zxy', 'Zyx', 'Zyy', 'Zyyb', 'survey1']>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can grab some of the datasets we created using the <span style=\"color:red\">get</span> method and specifying the dataset name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = myfile.get('Zxy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"Zxy\": shape (1000,), type \"<f8\">"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = myfile.get('Zyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"Zyy\": shape (1000, 1000), type \"<f4\">"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see all the groups and datasets in our HDF file by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_groups = [obj for obj in myfile if isinstance(myfile[obj],h5py.Group)]\n",
    "all_datasets = [obj for obj in myfile if isinstance(myfile[obj],h5py.Dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['survey1'] ['Zxx', 'Zxy', 'Zyx', 'Zyy', 'Zyyb']\n"
     ]
    }
   ],
   "source": [
    "print(all_groups, all_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what exists in the group *seismic*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['airborneEM_data', 'gravity_data', 'magnetic_data']>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile[\"survey1\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can grab a dataset within *seismic*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3 = myfile[\"survey1\"].get('gravity_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"gravity_data\": shape (50,), type \"<f4\">"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__d1__, __d2__ and __d3__ are HDF5 dataset objects. To convert these into arrays, use numpy's array method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1a = np.array(d1)\n",
    "d1a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2a = np.array(d2)\n",
    "d2a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d3a = np.array(d3)\n",
    "d3a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008,\n",
       "       0.009, 0.01 , 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017,\n",
       "       0.018, 0.019, 0.02 , 0.021, 0.022, 0.023, 0.024, 0.025, 0.026,\n",
       "       0.027, 0.028, 0.029, 0.03 , 0.031, 0.032, 0.033, 0.034, 0.035,\n",
       "       0.036, 0.037, 0.038, 0.039, 0.04 , 0.041, 0.042, 0.043, 0.044,\n",
       "       0.045, 0.046, 0.047, 0.048, 0.049, 0.05 , 0.051, 0.052, 0.053,\n",
       "       0.054, 0.055, 0.056, 0.057, 0.058, 0.059, 0.06 , 0.061, 0.062,\n",
       "       0.063, 0.064, 0.065, 0.066, 0.067, 0.068, 0.069, 0.07 , 0.071,\n",
       "       0.072, 0.073, 0.074, 0.075, 0.076, 0.077, 0.078, 0.079, 0.08 ,\n",
       "       0.081, 0.082, 0.083, 0.084, 0.085, 0.086, 0.087, 0.088, 0.089,\n",
       "       0.09 , 0.091, 0.092, 0.093, 0.094, 0.095, 0.096, 0.097, 0.098,\n",
       "       0.099, 0.1  , 0.101, 0.102, 0.103, 0.104, 0.105, 0.106, 0.107,\n",
       "       0.108, 0.109, 0.11 , 0.111, 0.112, 0.113, 0.114, 0.115, 0.116,\n",
       "       0.117, 0.118, 0.119, 0.12 , 0.121, 0.122, 0.123, 0.124, 0.125,\n",
       "       0.126, 0.127, 0.128, 0.129, 0.13 , 0.131, 0.132, 0.133, 0.134,\n",
       "       0.135, 0.136, 0.137, 0.138, 0.139, 0.14 , 0.141, 0.142, 0.143,\n",
       "       0.144, 0.145, 0.146, 0.147, 0.148, 0.149, 0.15 , 0.151, 0.152,\n",
       "       0.153, 0.154, 0.155, 0.156, 0.157, 0.158, 0.159, 0.16 , 0.161,\n",
       "       0.162, 0.163, 0.164, 0.165, 0.166, 0.167, 0.168, 0.169, 0.17 ,\n",
       "       0.171, 0.172, 0.173, 0.174, 0.175, 0.176, 0.177, 0.178, 0.179,\n",
       "       0.18 , 0.181, 0.182, 0.183, 0.184, 0.185, 0.186, 0.187, 0.188,\n",
       "       0.189, 0.19 , 0.191, 0.192, 0.193, 0.194, 0.195, 0.196, 0.197,\n",
       "       0.198, 0.199, 0.2  , 0.201, 0.202, 0.203, 0.204, 0.205, 0.206,\n",
       "       0.207, 0.208, 0.209, 0.21 , 0.211, 0.212, 0.213, 0.214, 0.215,\n",
       "       0.216, 0.217, 0.218, 0.219, 0.22 , 0.221, 0.222, 0.223, 0.224,\n",
       "       0.225, 0.226, 0.227, 0.228, 0.229, 0.23 , 0.231, 0.232, 0.233,\n",
       "       0.234, 0.235, 0.236, 0.237, 0.238, 0.239, 0.24 , 0.241, 0.242,\n",
       "       0.243, 0.244, 0.245, 0.246, 0.247, 0.248, 0.249, 0.25 , 0.251,\n",
       "       0.252, 0.253, 0.254, 0.255, 0.256, 0.257, 0.258, 0.259, 0.26 ,\n",
       "       0.261, 0.262, 0.263, 0.264, 0.265, 0.266, 0.267, 0.268, 0.269,\n",
       "       0.27 , 0.271, 0.272, 0.273, 0.274, 0.275, 0.276, 0.277, 0.278,\n",
       "       0.279, 0.28 , 0.281, 0.282, 0.283, 0.284, 0.285, 0.286, 0.287,\n",
       "       0.288, 0.289, 0.29 , 0.291, 0.292, 0.293, 0.294, 0.295, 0.296,\n",
       "       0.297, 0.298, 0.299, 0.3  , 0.301, 0.302, 0.303, 0.304, 0.305,\n",
       "       0.306, 0.307, 0.308, 0.309, 0.31 , 0.311, 0.312, 0.313, 0.314,\n",
       "       0.315, 0.316, 0.317, 0.318, 0.319, 0.32 , 0.321, 0.322, 0.323,\n",
       "       0.324, 0.325, 0.326, 0.327, 0.328, 0.329, 0.33 , 0.331, 0.332,\n",
       "       0.333, 0.334, 0.335, 0.336, 0.337, 0.338, 0.339, 0.34 , 0.341,\n",
       "       0.342, 0.343, 0.344, 0.345, 0.346, 0.347, 0.348, 0.349, 0.35 ,\n",
       "       0.351, 0.352, 0.353, 0.354, 0.355, 0.356, 0.357, 0.358, 0.359,\n",
       "       0.36 , 0.361, 0.362, 0.363, 0.364, 0.365, 0.366, 0.367, 0.368,\n",
       "       0.369, 0.37 , 0.371, 0.372, 0.373, 0.374, 0.375, 0.376, 0.377,\n",
       "       0.378, 0.379, 0.38 , 0.381, 0.382, 0.383, 0.384, 0.385, 0.386,\n",
       "       0.387, 0.388, 0.389, 0.39 , 0.391, 0.392, 0.393, 0.394, 0.395,\n",
       "       0.396, 0.397, 0.398, 0.399, 0.4  , 0.401, 0.402, 0.403, 0.404,\n",
       "       0.405, 0.406, 0.407, 0.408, 0.409, 0.41 , 0.411, 0.412, 0.413,\n",
       "       0.414, 0.415, 0.416, 0.417, 0.418, 0.419, 0.42 , 0.421, 0.422,\n",
       "       0.423, 0.424, 0.425, 0.426, 0.427, 0.428, 0.429, 0.43 , 0.431,\n",
       "       0.432, 0.433, 0.434, 0.435, 0.436, 0.437, 0.438, 0.439, 0.44 ,\n",
       "       0.441, 0.442, 0.443, 0.444, 0.445, 0.446, 0.447, 0.448, 0.449,\n",
       "       0.45 , 0.451, 0.452, 0.453, 0.454, 0.455, 0.456, 0.457, 0.458,\n",
       "       0.459, 0.46 , 0.461, 0.462, 0.463, 0.464, 0.465, 0.466, 0.467,\n",
       "       0.468, 0.469, 0.47 , 0.471, 0.472, 0.473, 0.474, 0.475, 0.476,\n",
       "       0.477, 0.478, 0.479, 0.48 , 0.481, 0.482, 0.483, 0.484, 0.485,\n",
       "       0.486, 0.487, 0.488, 0.489, 0.49 , 0.491, 0.492, 0.493, 0.494,\n",
       "       0.495, 0.496, 0.497, 0.498, 0.499, 0.5  , 0.501, 0.502, 0.503,\n",
       "       0.504, 0.505, 0.506, 0.507, 0.508, 0.509, 0.51 , 0.511, 0.512,\n",
       "       0.513, 0.514, 0.515, 0.516, 0.517, 0.518, 0.519, 0.52 , 0.521,\n",
       "       0.522, 0.523, 0.524, 0.525, 0.526, 0.527, 0.528, 0.529, 0.53 ,\n",
       "       0.531, 0.532, 0.533, 0.534, 0.535, 0.536, 0.537, 0.538, 0.539,\n",
       "       0.54 , 0.541, 0.542, 0.543, 0.544, 0.545, 0.546, 0.547, 0.548,\n",
       "       0.549, 0.55 , 0.551, 0.552, 0.553, 0.554, 0.555, 0.556, 0.557,\n",
       "       0.558, 0.559, 0.56 , 0.561, 0.562, 0.563, 0.564, 0.565, 0.566,\n",
       "       0.567, 0.568, 0.569, 0.57 , 0.571, 0.572, 0.573, 0.574, 0.575,\n",
       "       0.576, 0.577, 0.578, 0.579, 0.58 , 0.581, 0.582, 0.583, 0.584,\n",
       "       0.585, 0.586, 0.587, 0.588, 0.589, 0.59 , 0.591, 0.592, 0.593,\n",
       "       0.594, 0.595, 0.596, 0.597, 0.598, 0.599, 0.6  , 0.601, 0.602,\n",
       "       0.603, 0.604, 0.605, 0.606, 0.607, 0.608, 0.609, 0.61 , 0.611,\n",
       "       0.612, 0.613, 0.614, 0.615, 0.616, 0.617, 0.618, 0.619, 0.62 ,\n",
       "       0.621, 0.622, 0.623, 0.624, 0.625, 0.626, 0.627, 0.628, 0.629,\n",
       "       0.63 , 0.631, 0.632, 0.633, 0.634, 0.635, 0.636, 0.637, 0.638,\n",
       "       0.639, 0.64 , 0.641, 0.642, 0.643, 0.644, 0.645, 0.646, 0.647,\n",
       "       0.648, 0.649, 0.65 , 0.651, 0.652, 0.653, 0.654, 0.655, 0.656,\n",
       "       0.657, 0.658, 0.659, 0.66 , 0.661, 0.662, 0.663, 0.664, 0.665,\n",
       "       0.666, 0.667, 0.668, 0.669, 0.67 , 0.671, 0.672, 0.673, 0.674,\n",
       "       0.675, 0.676, 0.677, 0.678, 0.679, 0.68 , 0.681, 0.682, 0.683,\n",
       "       0.684, 0.685, 0.686, 0.687, 0.688, 0.689, 0.69 , 0.691, 0.692,\n",
       "       0.693, 0.694, 0.695, 0.696, 0.697, 0.698, 0.699, 0.7  , 0.701,\n",
       "       0.702, 0.703, 0.704, 0.705, 0.706, 0.707, 0.708, 0.709, 0.71 ,\n",
       "       0.711, 0.712, 0.713, 0.714, 0.715, 0.716, 0.717, 0.718, 0.719,\n",
       "       0.72 , 0.721, 0.722, 0.723, 0.724, 0.725, 0.726, 0.727, 0.728,\n",
       "       0.729, 0.73 , 0.731, 0.732, 0.733, 0.734, 0.735, 0.736, 0.737,\n",
       "       0.738, 0.739, 0.74 , 0.741, 0.742, 0.743, 0.744, 0.745, 0.746,\n",
       "       0.747, 0.748, 0.749, 0.75 , 0.751, 0.752, 0.753, 0.754, 0.755,\n",
       "       0.756, 0.757, 0.758, 0.759, 0.76 , 0.761, 0.762, 0.763, 0.764,\n",
       "       0.765, 0.766, 0.767, 0.768, 0.769, 0.77 , 0.771, 0.772, 0.773,\n",
       "       0.774, 0.775, 0.776, 0.777, 0.778, 0.779, 0.78 , 0.781, 0.782,\n",
       "       0.783, 0.784, 0.785, 0.786, 0.787, 0.788, 0.789, 0.79 , 0.791,\n",
       "       0.792, 0.793, 0.794, 0.795, 0.796, 0.797, 0.798, 0.799, 0.8  ,\n",
       "       0.801, 0.802, 0.803, 0.804, 0.805, 0.806, 0.807, 0.808, 0.809,\n",
       "       0.81 , 0.811, 0.812, 0.813, 0.814, 0.815, 0.816, 0.817, 0.818,\n",
       "       0.819, 0.82 , 0.821, 0.822, 0.823, 0.824, 0.825, 0.826, 0.827,\n",
       "       0.828, 0.829, 0.83 , 0.831, 0.832, 0.833, 0.834, 0.835, 0.836,\n",
       "       0.837, 0.838, 0.839, 0.84 , 0.841, 0.842, 0.843, 0.844, 0.845,\n",
       "       0.846, 0.847, 0.848, 0.849, 0.85 , 0.851, 0.852, 0.853, 0.854,\n",
       "       0.855, 0.856, 0.857, 0.858, 0.859, 0.86 , 0.861, 0.862, 0.863,\n",
       "       0.864, 0.865, 0.866, 0.867, 0.868, 0.869, 0.87 , 0.871, 0.872,\n",
       "       0.873, 0.874, 0.875, 0.876, 0.877, 0.878, 0.879, 0.88 , 0.881,\n",
       "       0.882, 0.883, 0.884, 0.885, 0.886, 0.887, 0.888, 0.889, 0.89 ,\n",
       "       0.891, 0.892, 0.893, 0.894, 0.895, 0.896, 0.897, 0.898, 0.899,\n",
       "       0.9  , 0.901, 0.902, 0.903, 0.904, 0.905, 0.906, 0.907, 0.908,\n",
       "       0.909, 0.91 , 0.911, 0.912, 0.913, 0.914, 0.915, 0.916, 0.917,\n",
       "       0.918, 0.919, 0.92 , 0.921, 0.922, 0.923, 0.924, 0.925, 0.926,\n",
       "       0.927, 0.928, 0.929, 0.93 , 0.931, 0.932, 0.933, 0.934, 0.935,\n",
       "       0.936, 0.937, 0.938, 0.939, 0.94 , 0.941, 0.942, 0.943, 0.944,\n",
       "       0.945, 0.946, 0.947, 0.948, 0.949, 0.95 , 0.951, 0.952, 0.953,\n",
       "       0.954, 0.955, 0.956, 0.957, 0.958, 0.959, 0.96 , 0.961, 0.962,\n",
       "       0.963, 0.964, 0.965, 0.966, 0.967, 0.968, 0.969, 0.97 , 0.971,\n",
       "       0.972, 0.973, 0.974, 0.975, 0.976, 0.977, 0.978, 0.979, 0.98 ,\n",
       "       0.981, 0.982, 0.983, 0.984, 0.985, 0.986, 0.987, 0.988, 0.989,\n",
       "       0.99 , 0.991, 0.992, 0.993, 0.994, 0.995, 0.996, 0.997, 0.998,\n",
       "       0.999])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's open and view the contents of the netCDF file we created in the previous section. To open a netCDF file from python, call the <span style=\"color:red\"> Dataset()</span> constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "netcdf_dataset = Dataset('oceantemp.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETCDF4\n"
     ]
    }
   ],
   "source": [
    "print(netcdf_dataset.file_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interrogate dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hight', 'lat', 'lon', 'time'])\n"
     ]
    }
   ],
   "source": [
    "print(netcdf_dataset.dimensions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'lat', size = 22\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 10\n",
      "\n",
      "<class 'netCDF4._netCDF4.Dimension'>: name = 'hight', size = 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(netcdf_dataset.dimensions['lat'])\n",
    "print(netcdf_dataset.dimensions['time'])\n",
    "print(netcdf_dataset.dimensions['hight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interrogate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['time', 'latitude', 'longitude', 'hight', 'temperature'])\n"
     ]
    }
   ],
   "source": [
    "print(netcdf_dataset.variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 latitude(lat)\n",
      "    units: degree_north\n",
      "unlimited dimensions: \n",
      "current shape = (22,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float64 time(time)\n",
      "    units: hours since 0001-01-01 00:00:00\n",
      "    calendar: gregorian\n",
      "unlimited dimensions: time\n",
      "current shape = (10,)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n",
      "<class 'netCDF4._netCDF4.Variable'>\n",
      "float32 temperature(time, lat, lon, hight)\n",
      "    units: Kelvin\n",
      "unlimited dimensions: time\n",
      "current shape = (10, 22, 28, 20)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(netcdf_dataset.variables['latitude'])\n",
    "print(netcdf_dataset.variables['time'])\n",
    "print(netcdf_dataset.variables['temperature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interrogate global and variable attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description = some fake ocean temperature data\n",
      "source = netCDF4 python module tutorial\n"
     ]
    }
   ],
   "source": [
    "# Find all netCDF global attributes\n",
    "\n",
    "for attr in netcdf_dataset.ncattrs():\n",
    "    print(attr, '=', getattr(netcdf_dataset,attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('time', <class 'netCDF4._netCDF4.Variable'>\n",
       "              float64 time(time)\n",
       "                  units: hours since 0001-01-01 00:00:00\n",
       "                  calendar: gregorian\n",
       "              unlimited dimensions: time\n",
       "              current shape = (10,)\n",
       "              filling on, default _FillValue of 9.969209968386869e+36 used),\n",
       "             ('latitude', <class 'netCDF4._netCDF4.Variable'>\n",
       "              float32 latitude(lat)\n",
       "                  units: degree_north\n",
       "              unlimited dimensions: \n",
       "              current shape = (22,)\n",
       "              filling on, default _FillValue of 9.969209968386869e+36 used),\n",
       "             ('longitude', <class 'netCDF4._netCDF4.Variable'>\n",
       "              float32 longitude(lon)\n",
       "                  units: degree_east\n",
       "              unlimited dimensions: \n",
       "              current shape = (28,)\n",
       "              filling on, default _FillValue of 9.969209968386869e+36 used),\n",
       "             ('hight', <class 'netCDF4._netCDF4.Variable'>\n",
       "              float32 hight(hight)\n",
       "                  units: meters\n",
       "              unlimited dimensions: \n",
       "              current shape = (20,)\n",
       "              filling on, default _FillValue of 9.969209968386869e+36 used),\n",
       "             ('temperature', <class 'netCDF4._netCDF4.Variable'>\n",
       "              float32 temperature(time, lat, lon, hight)\n",
       "                  units: Kelvin\n",
       "              unlimited dimensions: time\n",
       "              current shape = (10, 22, 28, 20)\n",
       "              filling on, default _FillValue of 9.969209968386869e+36 used)])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find variable attributes\n",
    "\n",
    "netcdf_dataset.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "netcdf_dataset.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command-line tools for HDF5 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are numerous command-line tools included in the HDF5 distribution to view, edit, convert and compare HDF5 files. Let's use our testfile.hdf5 file for the following examples. We will begin with <span style=\"color:red\">h5dump</span>, which enables the user to examine the contents of an HDF5 and dump those contents to an ASCII file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5dump -n geosurvey1.hdf5 # -n displays a list of the objects in a file\n",
    "\n",
    "h5dump -H geosurvey1.hdf5 # displays the header information only (no data)\n",
    "\n",
    "h5dump -d \"/survey1/gravity_data\" geosurvey1.hdf5 # display a specific dataset.\n",
    "\n",
    "h5dump -d \"survey1/gravity_data\" -o gravity.txt -y geosurvey1.hdf5 # converts specified dataset to ASCII file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">h5stat</span> can be used to print statistics about HDF5 files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5stat geosurvey1.hdf5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
